# A Large-scale Evaluation for Log Parsing Techniques: How Far are We?

This is the anonymous replication package for the ISSTA2024 submission **#448 "A Large-scale Evaluation for Log Parsing Techniques: How Far are We?"**. This repository contains the full datasets of LogPub, the source code of our benchmark, and **the complete version of our experimental results**, which can be found at [RQ_experiments](RQs_experiments/README.md) ðŸ”—.


## Repository Organization 

```
â”œâ”€â”€ 2k_dataset/
â”œâ”€â”€ full_dataset/
â”œâ”€â”€ benchmark/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ logparser/
â”‚   â”œâ”€â”€ old_benchmark/
â”‚   â”œâ”€â”€ LogPPT/ # contains the modified source code of LogPPT
â”‚   â”œâ”€â”€ UniParser/ # contains the source code of implemented UniParser
â”‚   â””â”€â”€ run_statistic_all.sh # the script to run all statistic-based log parsers
â”œâ”€â”€ result/
â”‚   â”œâ”€â”€ ...... # contains the output evaluation metric files
â”‚   â””â”€â”€ ...... # you can also download the recorded parsed results into here
â”œâ”€â”€ RQ_experiments/
â”‚   â”œâ”€â”€ RQ1/
â”‚       â”œâ”€â”€ RQ1_experiment.py
â”‚       â””â”€â”€ ...... # other output files
â”‚   â”œâ”€â”€ RQ2/
â”‚       â”œâ”€â”€ RQ2_experiment.py
â”‚       â””â”€â”€ ...... # other output files
â”‚   â”œâ”€â”€ RQ3/
â”‚       â”œâ”€â”€ RQ2_experiment.py
â”‚       â””â”€â”€ ...... # other output files
â”œâ”€â”€ util/
â”‚   â”œâ”€â”€ download_gdrive.py # code to automatically download the gdrive files
â”‚   â””â”€â”€ download_fulldataset.sh # script to download the full datasets, LogPub
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.MD
```

## Requirements

Owing to the large scale of the benchmark in the experiments, the requirements of the benchmark of all log parsers are:

- At least 16GB memory.
- At least 100GB storage.
- GPU (for LogPPT and UniParser).

**Installation**

1. Install ```python >= 3.8```
2. ```pip install -r requirements.txt```

## Download the LogPub Dataset

Due to the size limitation of Github, we have uploaded the proposed collection of datasets, LogPub, to the Google Drive for download, which can be downloaded via this [link](https://drive.google.com/file/d/1pV_FOa8KPzD2UwPyGPoo-12tyaBqOKNo/view?usp=share_link) ðŸ”— (zip: ~0.95G; unzip: 11G). After downloding, please extract the downloaded files to the folder `full_dataset` for follow-up proceeding.


## Large-scale benchmarking 


### Quick Demo using Drain

We give a demo script to run Drain on both Loghub-2k and LogPub, this will takes about 2-3 hours.

```bash
cd benchmark/
./demo.sh
```

### Evaluation of all 15 parsers

One can follow the steps to evaluate all parsers using Loghub-2k or the proposed Logpub datasets. The overall time cost is more than 48 hours.

- Run all statistic-based log parsers on Loghub-2k

```bash
cd benchmark/
./run_statistic_2k.sh
```

- Run all statistic-based log parsers on LogPub

```bash
cd benchmark/
./run_statistic_full.sh
```

- Run Semantic-based log parsers: LogPPT & UniParser

  Since these methods are quite different with other log parsers, and they requires a GPU to support efficient parsing, we seperate their environments from other log parsers. Please refer to the README file of [LogPPT](benchmark/LogPPT/README.md) or [UniParser](benchmark/UniParser/README.md) to use one-click script to parse and evaluate each log parsers respectively.
